\chapter{Multi-CCS}\label{multi-ccs}


\abstract*{
  We present Multi-CCS, an extension to CCS obtained by introducing one additional operator of prefixing $\underline\mu.p$, called {\em strong prefixing} (in opposition to normal prefixing $\mu.p$), with the capability of expressing transactions and, together with parallel composition, also multi-party synchronization.
}

\abstract{
  We present Multi-CCS, an extension to CCS obtained by introducing one additional operator of prefixing $\underline\mu.p$, called {\em strong prefixing} (in opposition to normal prefixing $\mu.p$), with the capability of expressing transactions and, together with  parallel composition, also multi-party synchronization.
}


\section{Lack of Expressiveness of CCS}

  As we have seen in Section \ref{CCS-turing}, CCS is a Turing-complete formalism, i.e., it has the ability to compute all the computable functions. Therefore, one may think that it is able to solve any kind of problems. Unfortunately this is not the case: Turing-completeness is not enough to ensure the solvability of all the problems in concurrency theory. For instance, it is well-known that a classic solution to the famous dining philosophers problem \cite{Dij71} (see below for details)  that assumes atomicity in the acquisition of the forks (or, equivalently, that requires a three-way synchronization among one philosopher and the two forks), cannot be provided  in CCS. An extension to CCS able to solve, among others, also this problem is the subject of this chapter.

%This important observation spurs an obvious question: when a formalism for concurrency is {\em complete}? 
%And with respect to what? Unfortunately, we still miss a definitive answer to this philosophical question.
%even if recent research is trying to
%unveil some aspects of this problem.

\subsection{Dining philosophers}
  This famous problem, proposed by Dijkstra in \cite{Dij71}, is defined as follows. Five philosophers sit at a round table, with a private plate, and each of the five forks is shared by two neighbors. Philosophers can think and eat; in order to eat, a philosopher has to acquire both forks that he shares with his neighbors, starting from the fork at his left and then the one at his right. All philosophers should behave the same, so the problem is intrinsically symmetric.

  A tentative solution in CCS to this problem can be given as follows, where for simplicity sake we consider the subproblem with two philosophers only. vThe forks can be defined by the constants $F_i$: 
  \begin{eqnarray*}
    F_i \eqdef  \overline{up_i}.\overline{dn_i}.F_i \; \;  \mbox{   for  }i = 0, 1  
  \end{eqnarray*}
  The two philosophers can be described as 
  \begin{eqnarray*}
    P_i \eqdef think.P_i +  up_i.up_{i+1}.eat.dn_i.dn_{i+1}.P_i  \; \;  \mbox{   for  }i = 0, 1 
  \end{eqnarray*}
  where $i+1$ is computed modulo $2$. 
  The whole system is 
  \begin{eqnarray*}
    DP \;  \eqdef \;  \restr{L}(((P_0\para P_1) \para F_0) \para F_1) 
  \end{eqnarray*}
  where $L = \{up_0, up_1, dn_0, dn_1\}$. 

  Clearly this na\"ive solution would cause a deadlock exactly when the two philosophers take the fork at their left at the same time and are waiting for the fork at their right. This is illustrated in Figure \ref{dp-dead-lts}, where the state $DP_d$ is a deadlock:

  $\begin{array}{llllllll}
      DP_d  & \eqdef  & \restr{L}(((P'_0\para P'_1) \para F'_0) \para F'_1) 
    \\
      P'_i & \eqdef &  up_{i+1}.eat.dn_i.dn_{i+1}.P_i  \; \;  \mbox{   for  }i = 0, 1
    \\
      F'_i & \eqdef & \overline{dn_i}.F_i \; \;  \mbox{   for  }i = 0, 1
    \\
 \end{array}$
  (You may also check this with $CWB$ for the original five philosophers case). 

  \begin{figure}[t]
    \centering
    %
    \caption{The two dining philosophers in CCS -- with deadlock.}
    \label{dp-dead-lts}
  \end{figure}


  A well-known solution to this problem is to break the symmetry by inverting the order of acquisition of the forks for the last philosopher. In our restricted case with two philosophers only, we have that
  \begin{eqnarray*}
      P''_0 \eqdef think.P''_0 +  up_0.up_1.eat.dn_0.dn_1.P''_0  
    \\
      P''_1 \eqdef think.P''_1 +  up_0.up_1.eat.dn_1.dn_0.P''_1 
  \end{eqnarray*}
  and the whole system is now
  \begin{eqnarray*}
    DP' \;  \eqdef \;  \restr{L}(((P''_0\para P''_1) \para F_0) \para F_1) 
  \end{eqnarray*}
  whose lts is depicted in Figure \ref{dp-asym-lts}. This solution works correctly (i.e., no deadlock is introduced), but it is not compliant to the specification that requires that all philosophers are defined in the same way.

  \begin{figure}[t]
    \centering
    %\input{CH-06/ccs-asym-dp-tex}
    \caption{The deadlock-free asymmetric solution of the two dining philosophers problem.}
    \label{dp-asym-lts}
  \end{figure}

  A simple, well-known solution is to force atomicity on the acquisition of the two forks so that either both are taken or none. This requirement can be approximately satisified in CCS as follows:
  \begin{eqnarray*}
    P_i''' \eqdef think.P_i''' +  up_i.(dn_i.P_i''' + up_{i+1}.eat.dn_i.dn_{i+1}.P_i''')  \; \;  \mbox{   for  }i = 0, 1 
  \end{eqnarray*}
  where, in case the second fork in unavailable, the philosopher may put down the first fork and return to its initial state. However, the new system
  \begin{eqnarray*}
    DP'' \;  \eqdef \;  \restr{L}(((P_0'''\para P_1''') \para F_0) \para F_1) 
  \end{eqnarray*}
  whose lts is depicted in Figure \ref{dp-live-lts-tex}, even if deadlock-free, may now diverge: the two philosophers may be engaged in a neverending livelock because the long operation of acquisition of the two forks may always fail.

  \begin{figure}[t]
    \centering
    %\input{CH-06/ccs-live-dp-tex}
    \caption{The symmetric solution of the two dining philosophers problem -- with livelock.}
    \label{dp-live-lts-tex}
  \end{figure}

Unfortunately, a solution that implements correctly the atomic acquisition of the two forks cannot be programmed in CCS because it lacks any construct for atomicity that would also enable a multiway synchronization between one philosopher and the two forks.  Indeed, Francez and Rodeh proposed in \cite{FR80} a distributed, symmetric, deterministic solution to the dining philosophers problem in  CSP \cite{Hoa85} by exploiting its  multiway synchronization capability. Moreover, Lehmann and Rabin demonstrated that such a solution  does not exist in a language with only binary synchronization such as CCS \cite{LR81}. Hence, if we want to solve this problem in CCS, we have to extend its capabilities somehow.

%We claim that the dining philosophers problem can be solved in a symmetric way -- without introducing 
%deadlocks or livelocks --
%in a process calculus 
%only if it allows for ternary synchronizations, a feature that CCS cannot offer. This claim is supported
%by  \cite{LV10}, that proves a strict expressiveness hierarchy among CCS-like calculi equipped with $n$-ary
%synchronizations: for instance, CCS$_2$ (i.e., ordinary CCS with binary synchronization) is strictly less expressive than
%CCS$_3$ (i.e., CCS which allows also for ternary synchronizations). 

\subsection{Strong prefixing: an operator for atomicity}

We enrich CCS with an additional operator $\underline{\alpha}.p$, called {\em strong prefixing}, where $\alpha$ 
is the first (observable) action of a transaction that continues with $p$
(provided that $p$ can complete the transaction). The operational SOS rules for strong prefixing are:\\

$\begin{array}{lcllcllcl}
 \mbox{(S-Pref$_1$)}  &  \bigfrac{p\deriv{\tau}p'}{\underline{\alpha}.p\deriv{\alpha}p'} & \quad & 
 \mbox{(S-Pref$_2$)}  & \bigfrac{p\deriv{\sigma}p' \quad \sigma \neq \tau}{\underline{\alpha}.p\deriv{\alpha\sigma}p'} &  \\
\end{array}$\\

\noindent
where $\sigma$ is a non-empty sequence of actions. 
Indeed, rule (S-pref$_2$) allows for the creation of
transitions labeled by non-empty sequences of actions. For instance, $\underline{a}.b.\nil$ can perform a single transition
labeled with the sequence $ab$, reaching state $\nil$. In order for $\underline{\alpha}.p$ to make a move, it is
necessary that $p$ can perform a transition, i.e., the rest of the transaction. Hence, if $p \deriv{\sigma} p'$ then 
$\underline{\alpha}.p \deriv{\alpha\sigma} p'$. Note that $\underline \alpha.\nil$ 
cannot perform any action, as $\nil$ is deadlocked. Usually, if a transition is labeled by 
$\sigma = \alpha_1 \ldots \alpha_{n-1} \alpha_n$, then all the
actions $\alpha_1 \ldots \alpha_{n-1}$ are due to strong prefixes, while $\alpha_n$ to a
normal prefix (or $\alpha_n$ is the last strong prefix before a $\tau$).
Rule (S-pref$_1$) ensures that $\tau$'s are never added in a sequence $\sigma$, hence ensuring that
in a transition $p \deriv{\sigma} p'$ either $\sigma = \tau$ or $\sigma$ is composed only of visible actions,
i.e., $\sigma$ ranges over ${\mathcal A} = (\mathcal{L} \cup \overline{\mathcal L})^+ \cup \{\tau\}$.

\begin{exercise}
Show that $\underline\alpha.\nil$ is strongly bisimilar to $\nil$. Show also that $\underline{a}.\tau.p \sim a.p$.
Draw the lts for $\underline{\alpha}.(a.\nil + b.\nil)$ and show that it
is bisimilar to $\underline{\alpha}.a.\nil \, + \, \underline{\alpha}.b.\nil$.
\fine
\end{exercise}

\begin{example}\label{true-phil}{\bf (Philosopher with atomic acquisition of forks)}
With the help of strong prefixing, we can now describe the two philosophers as:
\begin{eqnarray*}
P_i \eqdef think.P_i + \underline{up_i}.up_{i+1}.eat.\underline{dn_i}.dn_{i+1}.P_i  \; \;  \mbox{   for  }i = 0, 1 
\end{eqnarray*}
where $i+1$ is computed modulo $2$ and  the atomic sequence $up_i up_{i+1}$ models the atomic 
acquisition of the two forks. For simplicity,
we assume also that the release of the two forks is atomic, but this is not necessary for correctness.
The lts for $P_i$ is depicted in Figure \ref{ltsphil}.
\fine
\end{example}

\begin{figure}[t]
\centering
% \includegraphics[width=106mm]{philinter}
%\input{./CH-06/phil-solo-tex}
\caption{The labeled transition system for $P_i$.}
\label{ltsphil}
\end{figure}

What happens when we put a process $\underline{\alpha}.p$ in parallel with another process? For instance, if we take 
$q = \underline{a}.b.\nil \para c.\nil$, then the obvious generalization of the rules (Par$_1$) and (Par$_2$) 
of Table \ref{plain-ccs} ensure that the lts for 
$q$ is the left one reported in Figure \ref{abc-atomic}. If we compare this lts with the right one in Figure \ref{abc-atomic} 
for $q' = a.b.\nil \para c.\nil$,
we note that the sequence $acb$ is a trace for $q'$ but not for $q$: indeed, the atomic sequence $ab$ cannot be interleaved
with the action $c$ of the other parallel component, hence atomicity is really ensured.

\begin{figure}[t]
\centering
%\input{./CH-06/abc-tex}
\caption{Two labeled transition systems.}
\label{abc-atomic}
\end{figure}

    \subsection{Multiparty and Transactional Synchronization}

      Rule (Com) of Table \ref{plain-ccs} must be extended as now transitions are labeled on sequences of actions. The new rule is\\
      $\begin{array}{lcllcl}
	  \mbox{(S-Com)}  
	& 
	  \bigfrac{p\deriv{\sigma_1} p'\spazio q\deriv{\sigma_2}q'}{p\para q \deriv{\sigma}p'\para q'} 
	& 
	  \Sync(\sigma_1,  \sigma_2, \sigma) \\
      \end{array}$\\

      \noindent
      which has a side-condition on the possible synchronizability of sequences $\sigma_1$ and $\sigma_2$, whose result may be $\sigma$.

      When should $\Sync(\sigma_1, \sigma_2, \sigma)$ hold? As (S-Com) is a generalization of (Com), we should require that at least one synchronization takes place. Hence, if we assume that, e.g., $ \sigma_2$ is composed of a single action, then that action, say $\alpha$, must be synchronized with an occurrence of action $\overline{\alpha}$ in $\sigma_1 = \sigma' \overline{\alpha} \sigma''$. The resulting $\sigma$ is just $\sigma' \sigma''$ if at least one of the two is non-empty, otherwise (if $\sigma_1 = \overline{\alpha}$) the result is $\tau$. Note that when the resulting $\sigma$ is not $\tau$, then it can be used for further synchronization with some additional parallel components, hence allowing for multiparty synchronization.

      \begin{example}
	\label{multi-sync-phil}{\bf (Dining Philosophers with multiparty synchronization)}
	Continuing Example \ref{true-phil}, we can now define the complete two dining philosophers system $DP$ as follows:
	\begin{eqnarray*}
	  DP \;  \eqdef \;  \restr{L}(((P_0\para P_1) \para F_0) \para F_1) 
	\end{eqnarray*}
	where $L = \{up_0, up_1, dn_0, dn_1\}$. The operational semantics generates a finite-state  lts for $DP$, depicted in Figure \ref{ltsdining}. Here we want to show how the multiparty synchronization of a philosopher with the two forks takes place. The transition 
	\[
	  DP \deriv{\tau}  \restr{L}(((P'_0\para P_1) \para F'_0) \para F'_1) 
	\]
	where $P'_i = eat.\underline{dn_i}.dn_{i+1}.P_i$ and $F'_i = \overline{dn_i}.F_i$, can be proved as follows:
	\begin{center}

	  % \begin{sideways}
	  % \begin{minipage}{12cm}
	  non riesco a compilare il codice seguente:
\begin{verbatim}
\begin{prooftree}
                    \AxiomC{}
%
%                   \LeftLabel{\scriptsize{\mbox{(Pref)}}}
                  \UnaryInfC{$up_1.P'_0 \deriv{up_1}  P'_0$}
%
                  \AxiomC{$up_1 \neq \tau$}
%
%                 \LeftLabel{\scriptsize{\mbox{(S-Pref$_3$)}}}
                \BinaryInfC{$\underline{up_0}.up_1.P'_0 \deriv{up_0up_1}  P'_0$}
%
%               \LeftLabel{\scriptsize{\mbox{(Sum$_1$)}}}
              \UnaryInfC{$think.P_0 + \underline{up_0}.up_1.P'_0 \deriv{up_0up_1}  P'_0$}
%
%             \LeftLabel{\scriptsize{\mbox{(Cons)}}}
%             \RightLabel{$p_0 \eqdef think.p_0 + \underline{up_0}.up_1.p'_0$}
            \UnaryInfC{$P_0 \deriv{up_0up_1}  P'_0$}
%
%           \LeftLabel{\scriptsize{\mbox{(Par$_1$)}}}
          \UnaryInfC{$P_0\para P_1 \deriv{up_0up_1}  P'_0\para P_1$}
%
              \AxiomC{}
%
%             \LeftLabel{\scriptsize{\mbox{(Pref)}}}
            \UnaryInfC{$\overline{up_0}.F'_0 \deriv{\overline{up_0}} F'_0$}
%
%           \LeftLabel{\scriptsize{\mbox{(Cons)}}}
%           \RightLabel{$f_0 \eqdef  \overline{up_0}.f'_0$}
          \UnaryInfC{$F_0 \deriv{\overline{up_0}} F'_0$}
%
%         \LeftLabel{\scriptsize{\mbox{(S-Com)}}}
%         \RightLabel{$\Sync(up_0up_1,  \overline{up_0}, up_1)$}
        \BinaryInfC{$(P_0\para P_1) \para F_0 \deriv{up_1}  (P'_0\para P_1) \para F'_0$}
%
            \AxiomC{}
%
%           \LeftLabel{\scriptsize{\mbox{(Pref)}}}
          \UnaryInfC{$\overline{up_1}.F'_1 \deriv{\overline{up_1}} F'_1$}
%
%         \LeftLabel{\scriptsize{\mbox{(Cons)}}}
%         \RightLabel{$f_1 \eqdef  \overline{up_1}.f'_1$}
        \UnaryInfC{$F_1 \deriv{\overline{up_1}} F'_1$}
%
%       \LeftLabel{\scriptsize{\mbox{(S-Com)}}}
%       \RightLabel{$\Sync(up_1,  \overline{up_1}, \tau)$}
      \BinaryInfC{$((P_0\para P_1) \para F_0) \para F_1 \deriv{\tau}  ((P'_0\para P_1) \para F'_0) \para F'_1$}
%
%     \LeftLabel{\scriptsize{\mbox{(S-Res)}}}
%     \RightLabel{$L \cap n(\tau) = \emptyset$}
    \UnaryInfC{$\restr{L}(((P_0\para P_1) \para F_0) \para F_1) \deriv{\tau}  \restr{L}(((P'_0\para P_1) \para F'_0) \para F'_1)$}
%
%   \LeftLabel{\scriptsize{\mbox{(Cons)}}}
%   \RightLabel{$DP \;  \eqdef \;  \restr{L}(((p_0\para p_1) \para f_0) \para f_1)$}
  \UnaryInfC{$DP \deriv{\tau}  \restr{L}(((P'_0\para P_1) \para F'_0) \para F'_1)$}
\end{prooftree}
\end{verbatim}

	% \end{minipage}
	% \end{sideways}
	\fine
	\end{center}

      \end{example}


      \begin{figure}[t]
	\centering
	% \includegraphics[width=106mm]{philinter}
	%\input{./CH-06/philinter-tex}
	\caption{The labeled transition system for $DP$.}
	\label{ltsdining}
      \end{figure}

      \begin{exercise}\label{multi-sync-exer}
	Consider $p = \underline{a}.b.p'$, $q = \overline{b}.q'$ and $r = \overline{a}.r'$ and the whole system $P = \restr{a,b}((p \para q) \para r)$. Show that $P \deriv{\tau} \restr{a,b}((p' \para q') \para r')$, so the three processes have synchronized in one single atomic transaction.
      \fine
      \end{exercise}


      In general, $\Sync(\sigma_1, \sigma_2, \sigma)$ holds if $\sigma$ is obtained from an interleaving (possibly with synchronizations) of $\sigma_1$ and $\sigma_2$, where at least one synchronization has taken place. Relation $\Sync$ is defined by the inductive rules of Table~\ref{b-sync}, which make use of the auxiliary relation $\Int$, which is just as $\Sync$ without requiring that at least one synchronization occurs.\footnote{In the definition of $\Sync$ and $\Int$, with abuse of notation, we let $\sigma_1$ and $\sigma_2$ range over $\mathcal{A} \cup \{\epsilon\}$.}

      \begin{table}
	\hrulefill\\[-.5cm]
	\begin{center}
	  $\begin{array}{lclcl}
		\Sync(\alpha, \overline{\alpha}, \tau) 
	      &  
		\bigfrac{\Int(\sigma_1, \sigma_2, \sigma)}{\Sync(\alpha\sigma_1, \overline{\alpha}\sigma_2, \sigma)} 
	      &
		\bigfrac{\Sync(\sigma_1, \sigma_2, \tau)}{\Sync(\alpha\sigma_1, \sigma_2, \alpha)} 
	    \\
		\bigfrac{\Sync(\sigma_1, \sigma_2, \tau)}{\Sync(\sigma_1, \alpha\sigma_2, \alpha)} 
	      &
		\bigfrac{\Sync(\sigma_1, \sigma_2, \sigma) \quad \sigma \neq \tau}{\Sync(\alpha\sigma_1, \sigma_2, \alpha\sigma)} 
	      &
		\bigfrac{\Sync(\sigma_1, \sigma_2, \sigma) \quad \sigma \neq \tau}{\Sync(\sigma_1, \alpha\sigma_2, \alpha\sigma)} 
	    \\
	  \end{array}$
	\\\hrulefill\\
	  $\begin{array}{lllll}
		\Int(\alpha, \overline{\alpha}, \tau) 
	      &  
		\; \; \Int(\alpha, \epsilon, \alpha) 
	      &
		\; \;\Int(\epsilon, \alpha, \alpha) 
	      & 
		\bigfrac{\Int(\sigma_1, \sigma_2, \sigma)}{\Int(\alpha\sigma_1, \overline{\alpha}\sigma_2, \sigma)} 
	    \\
	  \end{array}$\\

	  $\begin{array}{lclcl}
	      \bigfrac{\Int(\sigma_1, \sigma_2, \tau)}{\Int(\alpha\sigma_1, \sigma_2, \alpha)} 
	    & 
	      \; \;  \bigfrac{\Int(\sigma_1, \sigma_2, \sigma) \quad \sigma \neq \tau}{\Int(\alpha\sigma_1, \sigma_2, \alpha\sigma)} 
	    & 
	      \; \; \bigfrac{\Int(\sigma_1, \sigma_2, \tau)}{\Int(\sigma_1, \alpha\sigma_2, \alpha)} 
	    &
	      \; \; \bigfrac{\Int(\sigma_1, \sigma_2, \sigma) \quad \sigma \neq \tau}{\Int(\sigma_1, \alpha\sigma_2, \alpha\sigma)} \\
	  \end{array}$
	\end{center}

	\hrulefill%\\[-.4cm]
	\caption{Synchronization relation $\Sync$ and interleaving relation $\Int$.}\label{b-sync}
      \end{table}


      \begin{exercise}
	Chek which of the following hold:\\
	$\begin{array}{lllllllll}
	      (1) 
	    & 
	      \Sync(\epsilon, a, a) 
	    & 
	      (2) 
	    & 
	      \Sync(ab, \bar{a}, b) 
	    & 
	      (3) 
	    & 
	      \Sync(a\tau, \bar{a}, \tau) 
	  \\
	      (4) 
	    & 
	      \Sync(a\bar{b}, bc, ac) 
	    & 
	      (5) 
	    & 
	      \Sync(a, \tau, a) 
	    & 
	      (6) 
	    & 
	      \Sync(ab, \overline{a}c, bc)
	  \\
	      (7) 
	    & 
	      \Sync(a\bar{b}, \bar{a}b, \tau) 
	    & 
	      (8) 
	    & 
	      \Sync(a \bar{b}, cb, ca) 
	    & 
	      (9) 
	    & 
	      \Sync(a \bar{b}, cb, ca\tau)
	  \\
	\end{array}$\\[-.4cm]
	\fine
      \end{exercise}
      	$\begin{array}{lll}
	    \Sync(\epsilon, a, a) no
	  & 
	      \inferrule{
		\inferrule{
		}{
		  \Int(b,\epsilon,b)
		}
	      }{
		\Sync(ab, \bar{a}, b)
	      }
	  &
	    \inferrule{
	      \inferrule{
	      }{
		\Int(\tau, \epsilon, \tau) 
	      }
	    }{
	      \Sync(a\tau, \bar{a}, \tau) 
	    }
	  \\\\
	    \inferrule{
		\inferrule{
		  \inferrule{
		  }{
		    \Int(\epsilon, c, c) 
		  }
		}{
		  \Sync(\bar{b}, bc, c) 
		}
	      \\
		c\neq \tau
	    }{
	      \Sync(a\bar{b}, bc, ac) 
	    }
	  &
	      \Sync(a, \tau, a) 
	  &
	      \Sync(ab, \overline{a}c, bc)
	  \\\\
	      \Sync(a\bar{b}, \bar{a}b, \tau) 
	  &
	      \Sync(a \bar{b}, cb, ca) 
	  &
	      \Sync(a \bar{b}, cb, ca\tau)
	  \\
	\end{array}$

\begin{exercise}
Prove that the following hold:

$\begin{array}{lllllllll}
(1) & \Sync(aa, \bar{a}\bar{a}, \tau) & (2) & \Sync(aa, \bar{a}\bar{a}, a\overline{a}) & (3) & \Sync(aa, \bar{a}\bar{a}, \overline{a}a)  \\
\end{array}$

\noindent
where both (2) and (3) can be proven in three different ways!
As you see, $\Sync$ is not a function of its first two arguments, but rather a relation, 
as the result of the synchronization of two sequences is not unique.
\fine
\end{exercise}

\begin{example}\label{trans-synch}{\bf (Transactional synchronization)} 
Assume we have two processes that want to synchronize
on a sequence of actions. 
This can be easily expressed in Multi-CCS. E.g., consider processes $p = \underline{a}.a.p'$ and
$q =\underline{\overline{a}}.\overline{a}.q'$ and the whole system $P = \restr{a}(p \para q)$. It is easy to observe
that $P \deriv{\tau} \restr{a}(p' \para q')$, so the two processes have synchronized in one single atomic transition.

Of course, it is possible to define transactional multi-party synchronization as well. 
For instance,  take
$p =\underline{\bar{a}}.\bar{b}.p'$ and $q = \underline{b}.\bar{a}.q'$, $r = \underline{a}.a.r'$, and the whole system $Q =
 \restr{a}((p \para q) \para r) \deriv{\tau} \restr{a}((p' \para q') \para r')$.
\fine
\end{example}


\section{Syntax and operational semantics} \label{syntax-sos-multi}

As for CCS, we assume to have a denumerable set ${\mathcal L}$ of channel names, its complementary 
set  $\overline{\mathcal L}$ of co-names, the set  ${\mathcal L}\cup\overline{\mathcal L}$ (ranged over by $\alpha, \beta, \ldots$)
of visible actions and the set of all actions $Act = {\mathcal L} \cup \overline{\mathcal L} \cup\{\tau\}$,
such that $\tau\not\in{\mathcal L}\cup\overline{\mathcal L}$, ranged over by $\mu$.

The process terms are generated by the following grammar, where we are using two syntactic categories: $p$, 
to range over sequential processes (i.e., processes that start sequentially), 
and $q$, to range over any kind of processes:

\[p ::= \nil \mid \mu.q \mid  \underline{\alpha}.q \mid p+p \; \; \mbox{  {\em sequential processes}}\]\\[-.9cm]
\[q ::= p \mid q\para q \mid \restr{a}q \mid C  \; \; \mbox{  {\em processes}}\]

\noindent
where the only new operator is the strong prefixing.
With abuse of notation, we denote with ${\mathcal P}$ the set of {\em processes}, containing any term $p$
such that its process constants in $Const(p)$ are
closed  and guarded.\footnote{The definition of guardedness for Multi-CCS constants is the same as
for CCS, reported in Definition \ref{def-guardednes}, in that it considers only (normal) prefixes, and not strong prefixes.
See also Remark \ref{guarded-rec}.} 

The  operational semantics for Multi-CCS is given by the labelled 
transition system $({\mathcal P},{\mathcal A}, \deriv{ })$, where the states are the processes
in ${\mathcal P}$, ${\mathcal A} = (\mathcal{L} \cup \overline{\mathcal L})^+ \cup \{\tau\}$
is the set of labels (ranged over by $\sigma$),
and $\deriv{ } \subseteq {\mathcal P} \times{\mathcal A}\times{\mathcal P}$ is the minimal 
transition relation generated by the rules listed in Table~\ref{m-rules}. 


\begin{table}[t]
{\renewcommand{\arraystretch}{2.8}
\hrulefill\\[-.4cm]

%{\renewcommand{\arraystretch}{2.8}
\begin{center}
$\begin{array}{lcllcl}
\mbox{(Pref)}  & \mu.p\deriv{\mu}p & & \; \; \;
\mbox{(Cong)} & \bigfrac{p \equiv p' \deriv{\sigma}q' \equiv q}{p\deriv{\sigma}q} \\
\mbox{(S-Pref$_1$)}  & \bigfrac{p\deriv{\tau}p'}{\underline{\alpha}.p\deriv{\alpha}p'} & & \; \; \;
\mbox{(S-Pref$_2$)}  & \bigfrac{p\deriv{\sigma}p' \quad \sigma \neq \tau}{\underline{\alpha}.p\deriv{\alpha\sigma}p'} \\
\mbox{(Sum$_1$)}  & \bigfrac{p\deriv{\sigma}p'}{p+q\deriv{\sigma}p'}  & & \; \; \;
%\mbox{(Cons)} & \bigfrac{p \deriv{\sigma}p'}{C\deriv{\sigma}p'}  & C\eqdef p \\
\mbox{(Par$_1$)}  & \bigfrac{p\deriv{\sigma}p'}{p\para q\deriv{\sigma}p'\para q} \\
\end{array}$

$\begin{array}{lcllcl}
\mbox{(S-Res)}  & \bigfrac{p\deriv{\sigma}p'}{\restr{a}p\deriv{\sigma}
\restr{a}p'} & a, \bar{a} \not\in n(\sigma) \\
\mbox{(S-Com)}  & \bigfrac{p\deriv{\sigma_1} p'\spazio q\deriv{\sigma_2}q'}{p
\para q \deriv{\sigma}p'\para q'} & \Sync(\sigma_1,  \sigma_2, \sigma) \\
\end{array}$

\hrulefill
\end{center}}
\caption{Operational semantics (symmetric rules for (Sum$_1$) and (Par$_1$) omitted)}\label{m-rules}
\end{table}


The new rules (S-Pref$_1$), (S-Pref$_2$) and (S-Com) have been already discussed.
Rule (S-Res) is slightly different, as it requires that no action in $\sigma$ can be $a$ or $\bar{a}$.
With $n(\sigma)$ we denote the set of all actions occurring in $\sigma$.

There is one further new rule, called  (Cong), which makes use of a structural congruence $\equiv$,
that is needed to overcome a shortcoming of parallel composition: without rule (Cong), parallel
composition is not associative.

\begin{example}\label{no-assoc}{\bf (Associativity)}
Consider process $P = \restr{a,b}((p \para q) \para r)$ of Exercise \ref{multi-sync-exer},
where $p = \underline{a}.b.p'$, $q = \overline{b}.q'$ and $r = \overline{a}.r'$. You should have already
seen that  $P \deriv{\tau} \restr{a,b}((p' \para q') \para r')$, so the three processes 
have synchronized in one single atomic transition. However, if we consider the very similar
process $P' = \restr{a,b}(p \para (q \para r))$, then we can see that $p$ is not able to synchronize
with both $q$ and $r$ at the same time! Indeed, $p \deriv{ab}p'$ while $q \para r \Nderiv{\overline{a}\overline{b}}$
and so no three-way synchronization can take place.

This means that parallel composition is not associative, unless a suitable structural congruence $\equiv$ 
is introduced, together with the operational rule (Cong), see Example \ref{multi-synch2}.

Similarly, in Example \ref{multi-sync-phil}, we have shown that the ternary synchronization among
the philosopher and the two forks can really take place:
\[
DP \deriv{\tau}  \restr{L}(((phil'_0\para phil_1) \para fork'_0) \para fork'_1) 
\]
However, if we consider the slightly different system 
\begin{eqnarray*}
DP' \;  \eqdef \;  \restr{L}(((phil_0\para phil_1) \para (fork_0 \para fork_1))
\end{eqnarray*}
then we can see that there is no way for the philosopher to synchronize with both forks! 
Indeed, $(fork_0 \para fork_1)$ is not able to generate an atomic sequence $\overline{up}_0 \overline{up}_1$.
Hence, also this example shows that parallel composition is not associative.
\fine
\end{example}

Since associativity is an important property that
any natural parallel composition operator should enjoy, we have to overcome this shortcoming by introducing
a structural congruence $\equiv$  and an associated operational rule (Cong).

Given a set of axioms $E$, the structural congruence $\equiv_E \subseteq {\mathcal P} \times {\mathcal P}$ is the 
congruence induced by the axioms in $E$. In other words, $p \equiv_E q$ if and only if $E \vdash p = q$, i.e., $p$ can be proved
equal to $q$ by means of the equational deductive system $D(E)$, composed of the rules in Table \ref{eq-ded}.
of Section \ref{Eq-deduction}.

Rule (Cong) makes use of a structural congruence $\equiv$ on process terms induced by the 
five equations in Table \ref{structural}.
%where it is assumed that these axioms are applied only to ground terms (i.e., the side-condition
%of each axiom is to be satisfied by the ground instantiation of the axiom).

\begin{table}[t]
{\renewcommand{\arraystretch}{1.8}
%\hrulefill\\[-.4cm]
\normalsize{

%{\renewcommand{\arraystretch}{2.8}
\begin{center}

\hrulefill

$\begin{array}{llrclllrrl}
{\bf E1} &\; \; &\; \;  (p \para q) \para r & = & p \para (q \para r) \\
{\bf E2} &\; \; &\; \; p \para q & = & q \para p \\
{\bf E3} &\; \; &\; \; A & = & q & \quad \mbox{ if $A \eqdef q$}\\
{\bf E4} &\; \; &\; \; \restr{a} (p \para q)  & = & p \para \restr{a}q &  \quad \mbox{ if $a$ not free in $p$}\\
{\bf E5} &\; \; &\; \; \restr{a} p & = &  \restr{b} (p\sost{b}{a}) & \quad \mbox{ if $b$ does not occur in $p$}\\
\end{array}$


\hrulefill

\end{center}}
}
\caption{Axioms generating the structural congruence $\equiv$.}\label{structural}
\end{table}


The first axiom {\bf E1} is for associativity of the parallel operator; the second one is for commutativity
of the parallel operator. Axiom {\bf E3} is for unfolding and explains 
why we have no explicit operational rule for handling constants in Table \ref{m-rules}: the transitions derivable from $C$
are those transitions derivable from the structurally congruent term $p$, if $C \eqdef p$. As a matter
of fact, the operational rule (Cons) for constants is subsumed by the following instance (Cong-c) of rule (Cong):

$\begin{array}{lcllcl}
\mbox{(Cons)} & \bigfrac{p \deriv{\sigma}p'}{C\deriv{\sigma}p'}  & C\eqdef p & & \; \; 
\mbox{(Cong-c)}  & \bigfrac{C \equiv p\deriv{\sigma}p' \equiv p'}{C\deriv{\sigma}p'} \\
\end{array}$

%The only difference is that $C$ and its body $p$ are the same state in the semantics with structural congruence. 
The rule (Cong) is anyway more general, and this will be useful in our setting, as we will see in 
Example \ref{ax-cons-needed}.
Axiom {\bf E4} allows for enlargement of the scope of restriction;
the last axiom is the so-called law of {\em alpha-conversion}, which makes use of syntactic 
substitution (see Section \ref{sec-fn-syntactic}). 

Rule (Cong) enlarges the set of transitions derivable from a given process $p$, as the following 
examples and exercises show. The intuition is that, given a process $p$, a transition is derivable from $p$
if it is derivable by any $p'$ obtained as a rearrangement in any order (or association) all of its 
sequential subprocesses.

\begin{example}\label{multi-synch2}{\bf (Associativity, again!)} 
Continuing Exercise \ref{multi-sync-exer} and Example \ref{no-assoc}, consider process 
$(p \para q) \para r$, where $p$ is a shorthand for $\underline{a}.b.p'$, $q$ for $\overline{b}.q'$ and $r$ for
$\overline{a}.r'$. You should have already
seen that  $(p \para q) \para r \deriv{\tau} (p' \para q') \para r'$ as follows:

\begin{center}
% \begin{sideways}
% \begin{minipage}{12cm}
\begin{verbatim}
\begin{prooftree}
                    \AxiomC{}
%
%                   \LeftLabel{\scriptsize{\mbox{(Pref)}}}
                  \UnaryInfC{$b.p' \deriv{b}  p'$}
%
                  \UnaryInfC{$\underline{a}.b.p' \deriv{ab}  p'$}
                  
%          \UnaryInfC{$p \deriv{ab}  p'$}

                    \AxiomC{}
%
%                   \LeftLabel{\scriptsize{\mbox{(Pref)}}}
                  \UnaryInfC{$\overline{b}.q' \deriv{\overline{b}}  q'$}

 %                 \UnaryInfC{$q \deriv{\overline{b}}  q'$}

%
%                 \LeftLabel{\scriptsize{\mbox{(S-Pref$_3$)}}}
                \BinaryInfC{$\underline{a}.b.p' \para \overline{b}.q' \deriv{a}  p' \para q'$}
%         
                                    \AxiomC{}
%
%                   \LeftLabel{\scriptsize{\mbox{(Pref)}}}
                  \UnaryInfC{$\overline{a}.r' \deriv{\overline{a}}  r'$}
%                 \UnaryInfC{$r \deriv{\overline{a}}  r'$}

%
                \BinaryInfC{$(\underline{a}.b.p' \para \overline{b}.q') \para \overline{a}.r' \deriv{\tau}  (p' \para q') \para r'$}
                

\end{prooftree}

\end{verbatim}

% \end{minipage}
% \end{sideways}
\end{center}


Now, consider
$p \para (q \para r)$. We have already
noticed that  $p \para (q \para r) \nonderiv{\tau} p' \para (q' \para r')$, if rule (Cong) is not available.
However, with the help rule (Cong), $p$ is now able to synchronize with both $q$ and $r$ at the same time as follows:

\begin{center}
$\begin{array}{lcllcl}
\bigfrac{p \para (q \para r)  \equiv (p \para q)  \para r   \deriv{\tau}  (p' \para q') \para r' \equiv p' \para (q' \para r')}
{p \para (q \para r) \deriv{\tau}  p' \para (q' \para r')} \\
\end{array}$
\end{center}

\noindent
Note that the needed structural congruence uses only the axiom for associativity.
\fine
\end{example}

\begin{exercise}\label{primo-exemple}
Consider $Q = p_1 \para \restr{a}(p_2 \para p_3)$, where $p_1 = \underline{b}.c.p'_1$, $p_2 = \overline{b}.p'_2$ 
and $p_3 = \overline{c}.p'_3$. Assume $a \not\in fn(p'_1)$. Show that $Q \equiv Q'$, 
where $Q' = \restr{a}((p_1 \para p_2) \para p_3)$.
({\em Hint:} You also need the axiom {\bf E4} for scope enlargement.) 
Show also that $Q \deriv{\tau} Q''$, where $Q'' =  p'_1 \para \restr{a}(p'_2 \para p'_3)$.
\fine
\end{exercise}

\begin{exercise}
Consider $Q = p_1 \para \restr{a}(p_2 \para p_3)$ of the Exercise \ref{primo-exemple}. Show that, by taking a new name $d$
not occurring free in $Q$, $Q \equiv \restr{d}((p_1 \para p_2\sost{d}{a}) p_3\sost{d}{a})$.
({\em Hint:} You need axioms {\bf E1}, {\bf E4} and {\bf E5}.) 
Show also that $Q \deriv{\tau} Q''$, where $Q'' =  p'_1 \para \restr{a}(p'_2 \para p'_3)$, even in case $a \in fn(p_1)$.
\fine
\end{exercise}


\begin{example}\label{comm-needed}
In order to see that also the commutativity axiom {\bf E2} may be useful, consider process $p = 
 (\underline{a}.c.0 | b.0) | (\overline{a}.0 | \underline{\overline{b}}.\overline{c}.0)$. Such a process
 can do a four-way synchronization $\tau$ to $q = (\nil \para \nil) \para (\nil \para \nil)$, because $p' = 
 (\underline{a}.c.0 | \overline{a}.0) | (b.0 | \underline{\overline{b}}.\overline{c}.0)$, which is structurally 
 congruent to $p$, can perform $\tau$ reaching $q$.
Without rule (Cong), process $p$ could not perform such a multiway synchronization.
\fine
\end{example}

\begin{example}\label{ax-cons-needed}
In order to see that also the unfolding axiom {\bf E3} may be useful, 
consider $R = \underline{a}.c.0 | A$, where $A \eqdef \overline{a}.0 \para \overline{c}.0$. Without rule (Cong) 
(and axiom {\bf E3} of Table \ref{structural}),
it is not possible to derive $R \deriv{\tau} 0 \para (0 \para 0)$. 
\fine
\end{example}


\begin{remark}\label{guarded-rec}{\bf (Guardedness prevents infinitely-branching sequential processes)} 
We assume that each process constant in a defining equation occurs
inside a normally prefixed subprocess $\mu.q$. This will prevent infinitely branching sequential processes.
E.g, consider the non legal process $A  \eqdef  \underline{a}.A + b.\nil$.
According to the operational rules, $A$ has infinitely many transitions leading to $\nil$, each of the form $a^nb$, for 
$n = 0, 1, ...$. 
In fact, under guardedness, the set of terms generated by 
\[ p ::= \nil \mid  \mu.p \mid  \underline{\alpha}.p \mid p+p  \mid  C\]
defines, up to isomorphism, the set of transition systems labeled on ${\mathcal A} = 
(\mathcal{L} \cup \overline{\mathcal L})^+ \cup \{\tau\}$ with finitely many states and transitions.
\fine
\end{remark}

\begin{exercise}
Following the proof of Theorem \ref{representability-fs}, prove the statement above.
\fine
\end{exercise}


\section{Behavioural semantics}

Ordinary bisimulation equivalence, usually called {\em interleaving bisimulation} equivalence, 
enjoys some expected algebraic properties, but unfortunately it
is not a congruence for parallel composition. In order to find a suitable compositional semantics for 
Multi-CCS,  we define an alternative operational
semantics, where transitions are labeled by multiset of concurrently executable sequences. Ordinary bisimulation
equivalence 
over this enriched transition system is called {\em step bisimulation} equivalence. 
We will prove that step bisimulation equivalence is a congruence, even if not the coarsest congruence 
contained in interleaving bisimulation equivalence. In order to find such a coarsest congruence,
we propose a novel semantics, called {\em linear-step bisimilarity}; we also axiomatize it for 
finite Multi-CCS processes.

\subsection{Interleaving semantics}

Two terms $p$ and $q$ are {\em interleaving bisimilar}, written
$p\sim q$, if there exists a strong bisimulation $R$ such that $(p,q)\in R$.
Interleaving bisimulation equivalence enjoys some expected algebraic properties. 


\begin{proposition}\label{prop1}
Let $p, q \in {\mathcal P}$ be Multi-CCS processes. If $p \equiv q$ then $p \sim q$.

\proof
It is enough to check that relation $R = \{(p, q) \mid p \equiv q\}$ is a bisimulation.
If $(p, q) \in R$ and $p \deriv{\sigma} p'$, then by rule (Cong)
also $q \deriv{\sigma} p'$ and $(p', p') \in R$. Symmetrically, if $q$ moves first.
\fine
\end{proposition}

Note that an obvious consequence of the above Proposition is that the following 
algebraic laws hold for strong bisimilarity $\sim$, for all $p, q, r \in {\mathcal P}$:\\

$\begin{array}{llll}
(1) & p \para (q \para r) \; \sim \; (p \para q) \para r \\
(2) & p \para q\; \sim \; q \para p \\
(3) & C \; \sim \; p \; \; \; \mbox{ if $C \eqdef p$ }\\
(4) & \restr{x}(p \para q) \; \sim \;  p \para \restr{x}q \mbox{  if } x \not\in fn(p) \\
(5) & \restr{x}p \; \sim \;  \restr{y} (p\sost{y}{x}) \mbox{  if } y \not\in fn(p) \\
\end{array}$\\

Other properties hold for bisimilarity, as the following Proposition shows.

\begin{proposition}\label{prop2}
Let $p, q, r \in {\mathcal P}$ be processes. Then the following holds:\\

$\begin{array}{llll}
(6) & (p + q) + r \; \sim \; p + (q +r)  &
(7) & p + q\; \sim \; q + p  \\
(8) & p + \nil \; \sim \;  p  &
(9) & p + p \; \sim \; p \\
(10) & p \para \nil \; \sim \;  p &
(11) & \restr{x}\restr{y}p \; \sim \;  \restr{y}\restr{x}p\\
(12) & \restr{x} \nil \; \sim \; \nil &
\end{array}$

\proof 
The proof is standard and is similar to the proofs of Propositions \ref{aci-+}, \ref{aci-parallel} and \ref{restr-law}.
E.g., for (7) it is enough to prove that relation $R = \{ ((p+q),(q+p) \mid p,q \in   {\mathcal P} \} \cup 
\{ (p,p) \mid p \in  {\mathcal P} \} $ is a strong bisimulation. 
\fine
\end{proposition}

\begin{exercise}
Prove the laws (6)-(12) above, by providing a suitable bisimulation relation for each law.
\fine
\end{exercise}


A few properties of strong prefixing are as follows:

\begin{proposition}\label{prop}
Let $p, q \in {\mathcal P}$ be processes. Then the following holds:\\

$\begin{array}{lllllr}
(1) & \underline\alpha.(p + q)  \; \sim \;   \underline\alpha.p +  \underline\alpha.q & \; \;
(2) &  \underline\alpha.\nil  \; \sim \;   \nil & \; \;
%(3) &  \underline\tau.p   \; \sim \;  p  &  \; \;
(3) &  \underline\alpha.\tau.p   \; \sim \;  \alpha.p \\
\end{array}
$\\[-.8cm]

\fine
\end{proposition}

\begin{exercise}
Prove the strong prefixing laws (1)-(3) above, by providing a suitable bisimulation relation for each law.
\fine
\end{exercise}

Interleaving bisimulation is a congruence for almost all the operators of Multi-CCS, in particular for strong prefixing.

\begin{proposition}
If $p \sim q$, then the following hold:
\begin{enumerate}
\item  $\mu.p \sim \mu.q \quad$ for all $\mu \in Act$,
\item $\underline{\alpha}.p \sim \underline{\alpha}.q \quad$ for all $\alpha \in \mathcal{L}\cup\overline{\mathcal{L}}$
\item $p + r \sim q + r \quad $ for all  $r \in \mathcal{P}$,
\item $\restr{a}p \sim \restr{a}q \quad$ for all $a \in \mathcal{L}$.
\end{enumerate}

\proof
The proof is very similar to the one for Theorem \ref{strong-congruence}. E.g., 
assume $R$ is a bisimulation such that $(p, q) \in R$.
Then, for case 2,  consider relation $R_2 = \{(\underline\alpha.p, \underline\alpha.q)\} \cup R$. 
It is easy to check that $R_2$ is a bisimulation.
\fine
\end{proposition}

Unfortunately, $\sim$ is not a congruence for parallel composition, as the following example shows.

\begin{example}\label{sim-no-cong}{\bf (No congruence for parallel composition)}
Consider processes $p = \overline{a}.\overline{a}.\nil$ and  $q = \overline{a}.\nil \para \overline{a}.\nil$.
Clearly, $p \sim q$. However, context $\mathcal{C}[-] =  - \para \underline{a}.\underline{a}.c.\nil$ is such
that $\mathcal{C}[p] \not\sim \mathcal{C}[q]$, because the latter can perform $c$, i.e., 
$\mathcal{C}[q] \deriv{c} (\nil \para \nil) \para \nil$, 
while $\mathcal{C}[p]$ cannot. The reason for this
difference is that the process $\underline{a}.\underline{a}.c.\nil$ can react with a number of concurrently active components
equal to the length of the trace it can perform. Hence, a congruence semantics 
for parallel composition must distinguish $p$ and $q$ on the basis of their different degree of parallelism.
\fine
\end{example}

\subsection{Step Semantics}

Multi-CCS can be equipped with a step semantics, i.e., a semantics where each transition is labeled by a finite (multi-)set of 
sequences that concurrent subprocesses can perform at the same time. This equivalence was originally introduced 
over Petri nets \cite{NT84}, while \cite{Mil85} is the first step semantics
defined over lts's.

The  step operational semantics for Multi-CCS is given by the lts 
$({\mathcal P},{\mathcal B}, \derivas{ })$, where the states are the processes
in ${\mathcal P}$, ${\mathcal B} = {\mathcal M}_{fin}({\mathcal A})$ 
is the set of labels (ranged over by $M$),
and $\derivas{ } \subseteq {\mathcal P}\times{\mathcal B}\times{\mathcal P}$ is the minimal 
transition relation generated by the rules listed in Table~\ref{step-rules}. 

Note that rules (S-pref$_1^s$) and (S-pref$_2^s$) assume that the transition in the premise 
is sequential, i.e., composed of one single sequence. Note also that rule (S-Com$^s$)
uses an additional auxiliary relation $\MSync$, defined in Table~\ref{Msync}, where $\oplus$ denotes multiset union.
The intuition behind the definition of rule (S-Com$^s$) and $\MSync$ is that, whenever two parallel processes 
$p$ and $q$ perform steps $M_1$ and $M_2$, then we can put all the sequences together -- $M_1 \oplus M_2$ --
and see if $\MSync(M_1 \oplus M_2, \overline{M})$ holds. The resulting $\overline{M}$ may be just 
$M_1 \oplus M_2$ (hence no synchronization takes place), according to axiom $\MSync(M, M)$, 
or the $M'$ we obtain from the application of the rule:
select two sequences $\sigma_1$ and $\sigma_2$ from $M_1 \oplus M_2$, synchronize them producing $\sigma$,
then recursively apply $\MSync$ to $M_1 \oplus M_2 \setminus \{\sigma_1, \sigma_2\} \cup \{\sigma\}$ to obtain $M'$.
This procedure of synchronizing sequences may go on until pairs of synchronizable sequences can be found, 
but may also stop in any moment due to the axiom $\MSync(M, M)$.

It is interesting to observe that these step operational rules do not make use of structural congruence $\equiv$. The same
operational effect of rule (Cong) is here ensured by relation $\MSync$ that allows for multiple synchronization 
of concurrently active subprocesses. 


\begin{table}[t]
\hrulefill\\[-.4cm]

{\renewcommand{\arraystretch}{2.5}
\begin{center}
$\begin{array}{lcllllcl}
\mbox{(Pref$^s$)}  & \mu.p\derivas{\{\mu\}}p & \qquad &
\mbox{(Con$^s$)} & \bigfrac{p\derivas{M}p'}{C \derivas{M}p'}& C \eqdef p &  \\
\mbox{(S-Pref$_1^s$)}  & \bigfrac{p\derivas{\{\tau\}}p'}{\underline{\alpha}.p\derivas{\{\alpha\}}p'} & \qquad &
\mbox{(S-Pref$_2^s$)}  & \bigfrac{p\derivas{\{\sigma\}}p' \quad \sigma \neq \tau}{\underline{\alpha}.p\derivas{\{\alpha\sigma\}}p'} \\

%\mbox{(Sum$_2^s$)}  & \bigfrac{q\derivas{M}q'}{p+q\derivas{M}q'}  & \\
%\mbox{(Par$_2^s$)}  & \bigfrac{q\derivas{M}q'}{p\para q\derivas{M}p\para q'} &  \\
\mbox{(Par$_1^s$)}  & \bigfrac{p\derivas{M}p'}{p\para q\derivas{M}p'\para q} & \qquad &
\mbox{(Sum$_1^s$)}  & \bigfrac{p\derivas{M}p'}{p+q\derivas{M}p'} \\
\end{array}$

$\begin{array}{lcllcl}

\mbox{(Res$^s$)}  & \bigfrac{p\derivas{M}p'}{\restr{a}p\derivas{M}
\restr{a}p'} & \forall \sigma \in M\, \; a, \bar{a} \not\in n(\sigma)\;  &\\

\mbox{(S-Com$^s$)}  & \bigfrac{p\derivas{M_1} p'\spazio q\derivas{M_2}q'}{p
\para q \deriv{M}p'\para q'} & \MSync(M_1 \oplus M_2, M) &\\
\end{array}$

\hrulefill
\end{center}}
\caption{Step operational semantics (symmetric rules for (Sum$_1^s$) and (Par$_1^s$) omitted).}\label{step-rules}
\end{table}


\begin{table}[t]
\hrulefill\\[-.4cm]
\begin{center}

$\begin{array}{lcr}
\MSync(M, M) & \qquad \quad & \bigfrac{\Sync(\sigma_1, \sigma_2, \sigma) \; \;  \; \MSync(M\oplus\{\sigma\}, M')}
{\MSync(M \oplus \{\sigma_1, \sigma_2\}, M' )}  
\end{array}$

\end{center}
\hrulefill
\caption{Step synchronization relation}\label{Msync}
\end{table}

%\begin{example}
%Continuing Example \ref{multi-synch2}, consider process $P' =  \restr{a,b}(p \para (q \para r))$ 
%where $p = \underline{a}.b.p'$, $q = \overline{b}.q'$ and $r = \overline{a}.r'$. 
%We showed that transition   $P' \deriv{\tau} \restr{a,b}(p' \para (q' \para r'))$ is derivable. Now we show that
%transition $P' \derivas{\{\tau\}} \restr{a,b}(p' \para (q' \para r'))$ is derivable in the step transition system as follows:
%
%
%{\bf Metterci l'albero della dimostrazione}
%\fine
%\end{example}

In general, one can prove the following obvious fact.

\begin{proposition}\label{step>int}
Let $p, q \in {\mathcal P}$ be processes. Then the following hold:
\begin{enumerate}
\item If $p \derivas{\{\sigma\}} q$, then $p \deriv{\sigma} q$.
\item If $p \deriv{\sigma} q$, then $\exists q' \equiv q$ such that $p \derivas{\{\sigma\}} q'$.
\end{enumerate}

\proof (Sketch) The proof of (1) is by induction on the proof of $p \derivas{\{\sigma\}} q$. All the cases are trivial,
except when (S-Com$^s$) is used. In such a case, 
the premises are $p_1 \derivas{M_1} q_1$ and $p_2 \derivas{M_2} q_2$, with $p = p_1 \para p_2$ and
$q = q_1 \para q_2$. For each sequence $\sigma_j^k \in M_k$, there is a subprocess $p_j^k$ of $p_k$ that 
performs it, for $k = 1, 2$.
The actual proof of relation $\MSync(M_1 \oplus M_2, \{\sigma\})$ tells in which order the parallel 
subcomponents $p_j^k$ are to be arranged by means of the structural congruence.

The proof of (2) is by induction on the proof of $p \deriv{\sigma} q$. We cannot prove the
stronger result $p \derivas{\{\sigma\}} q$, because of the free use of structural congruence; e.g., 
$\mu.(p \para (q \para r)) \deriv{\mu} ((p \para q) \para r)$ (due to (Cong)), 
while $\mu.(p \para (q \para r))$ cannot reach $((p \para q) \para r)$ in the step transition system.
\fine
\end{proposition}



We call {\em step equivalence}, denoted $\sim_{step}$, the bisimulation equivalence on the step transition 
system of Multi-CCS. Step equivalence $\sim_{step}$ is more discriminating than ordinary interleaving bisimulation $\sim$. 
For instance, $(a.\nil \para b.\nil) \sim a.b.\nil + b.a.\nil$
but the two are not step bisimilar as only the former can perform a transition labeled by $\{a, b\}$.
This is formally proved as follows.

\begin{proposition}\label{step->int}
For any pair of processes $p, q \in \mathcal{P}$, if $p \sim_{step} q$ then $p \sim q$.

\proof
Let $R$ be a step bisimulation (i.e., a bisimulation over the step lts) such that $(p, q) \in R$.
Then, it is easy to prove that $R$ is an interleaving bisimulation up to $\sim$ (Definition \ref{up-to-bis-def}) by
%$\equiv \circ \, R \, \circ \equiv$ is an interleaving bisimulation containing the pair $(p, q)$ 
%(where $\circ$ is the operation of relation composition). To prove this, we can resort to 
Proposition \ref{step>int} and Proposition \ref{prop1}. 
%and Lemma \ref{cong>step}.
\fine
\end{proposition}

For step bisimilarity $\sim_{step}$ we have very similar algebraic laws as for interleaving bisimilairty $\sim$. 
In particular, the following Proposition shows that the structural congruence is a step bisimilarity, hence 
the five laws listed after Proposition \ref{prop1} hold also for it.

\begin{proposition}\label{cong>step}
Let $p, q \in {\mathcal P}$ be processes. If $p \equiv q$ then $p  \sim_{step} q$.

\proof One has to show that for each equation $p = q$ generating $\equiv$, we have that $p  \sim_{step} q$.
The only non-trivial case is for associativity $(p \para q) \para r \; = \; p \para (q \para r)$
where one has to prove the following auxiliary lemma: if $p  \derivas{M_1} p'$, $q  \derivas{M_2} q'$
and $r \derivas{M_3} r'$, then for all $M, M'$ such that $\Sync(M_1 \oplus M_2, M')$ and $\Sync(M' \oplus M_3, M)$,
there exists $N$ such that $\Sync(M_2 \oplus M_3, N)$ and $\Sync(M_1 \oplus N, M)$. 
The thesis of this lemma follows by observing that such $M$ can be obtained as $\Sync(M_1 \oplus M_2 \oplus M_3, M)$.
\fine
\end{proposition}

\begin{exercise}
Prove that the seven laws of Proposition \ref{prop2} hold also when $\sim$ is replaced by $\sim_{step}$.
\fine
\end{exercise}

\begin{exercise}
Prove that $(a.\nil \para b.\nil) + a.b.\nil \, \sim_{step} \, a.\nil \para b.\nil$.\footnote{Strictly speaking, the term
$(a.\nil \para b.\nil) + a.b.\nil$ is not legal, as sum is unguarded; however, a completely equivalent guarded term
can be provided in Multi-CCS as $\restr{c}((a + \overline{c}) \para (b + \underline{c}.a.b))$.}
\fine
\end{exercise}

\begin{figure}
\centering
%\input{CH-06/step-dining-tex}
\caption{The step labeled transition system for $DP$. 
}
\label{stepdining}
\end{figure}

\begin{example} {\bf (Proving mutual exclusion)} Let us consider the system $DP$ of Example \ref{multi-sync-phil}. 
A proof that $DP$ acts correctly, i.e., it never allows both philosophers to eat at the same time, can be given by
inspecting its step transition system (see Figure \ref{stepdining}). As a matter of fact, the step $\{eat, eat\}$ is not present.
\fine
\end{example}

\begin{theorem}\label{cong-step}{\bf (Congruence)}
If $p \sim_{step} q$, then the following hold:
\begin{enumerate}
\item  $\mu.p \sim_{step} \mu.q \quad$ for all $\mu \in Act$,
\item $\underline{\alpha}.p \sim_{step} \underline{\alpha}.q \quad$ for all $\alpha \in \mathcal{L}\cup\overline{\mathcal{L}}$
\item $p + r \sim_{step} q + r \quad $ for all  $r \in \mathcal{P}$,
\item $p \para r \sim_{step} q \para r \quad  $ for all  $r \in \mathcal{P}$,
\item $\restr{a}p \sim_{step} \restr{a}q \quad$ for all $a \in \mathcal{L}$.
\end{enumerate}

\proof
Assume $R$ is a step bisimulation (i.e., an ordinary bisimulation on the step transition system)
containing the pair $(p, q)$.

Case (1) can be proven by considering relation $R_1 = R \cup \{(\mu.p, \mu.q)\}$: by (Pref$^s$), 
$\mu.p \derivas{\{\mu\}} p$ and $\mu.q \derivas{\{\mu\}} q$, with $(p, q) \in R$, hence $R_1$ is a bisimulation.

Case (2) can be proven by considering relation $R_2 = R \cup \{(\underline\alpha.p, \underline\alpha.q)\}$. 
If $p \derivas{\{\tau\}} p'$, then by rule (S-Pref$_1^s$) $\underline\alpha.p \derivas{\{\alpha\}} p'$.
As $(p, q) \in R$, also $q \derivas{\{\tau\}} q'$ with $(p', q') \in R$. Hence, also $\underline\alpha.q \derivas{\{\alpha\}} q'$
with $(p', q') \in R_2$, as required. If $p \derivas{\{\sigma\}} p'$ and $\sigma \neq \tau$, then by rule (S-Pref$_2^s$) 
$\underline\alpha.p \derivas{\{\alpha\sigma\}} p'$. As $(p, q) \in R$, also $q \derivas{\{\sigma\}} q'$ with $(p', q') \in R$.
Hence, also $\underline\alpha.q \derivas{\{\alpha\sigma\}} q'$ with $(p', q') \in R_2$, as required. 

Case (3) can be proven by showing that relation $R_3 = \{(p + r, q + r) \mid 
r \in \mathcal{P}\} \cup R \cup \{(r, r) \mid r \in \mathcal{P}\}$ is a step bisimulation.

Case (4) can be proven by showing that relation $R_4 =  \{(p' \para r', q' \para r') \mid (p', q') \in R, r' \in \mathcal{P}\}$ 
 is a step bisimulation. 

Case (5) can be proven by showing that relation $R_5 =  \{(\restr{a}p', \restr{a}q') \mid (p', q') \in R\}$
 is a step bisimulation.
\fine
\end{theorem}

\begin{exercise}
Prove that  $\underline{a}.(b.\nil \para c.\nil)
\sim_{step} (\underline{a}.(b.c.\nil + c.b.\nil)$, even if $b.\nil \para c.\nil \not\sim_{step} b.c.\nil + c.b.\nil$.
\fine
\end{exercise}

Theorem \ref{cong-step}(4) and Proposition \ref{step->int} ensure that 
for any pair of processes $p, q \in \mathcal{P}$, if $p \sim_{step} q$ then,  for all  $r \in \mathcal{P}$, $p \para r \sim q \para r$.
One may wonder if the reverse hold, i.e., if for all  $r \in \mathcal{P}$, $p \para r \sim q \para r$ can we conclude that 
$p \sim_{step} q$? If this is the case, we can say that step equivalence is the {\em coarsest congruence} contained in
interleaving bisimulation. The answer to this question is negative, as the following examples show.

\begin{example}\label{no-tau-coarsest}
Take processes $p = \tau.\tau.\nil$ and $q = \tau \para \tau$.
It is not difficult to see that for all  $r \in \mathcal{P}$, $p \para r \sim q \para r$; however, $p \not\sim_{step} q$ 
as only the latter can perform the step $\{\tau, \tau\}$. 
\fine
\end{example}

\begin{example}\label{no-coarsest}
Take $p = (a \para a) + \underline{a}.a.\nil$\footnote{Actually, this term is not legal, as sum is unguarded; however, 
a completely equivalent guarded term is $\restr{c}((a + \overline{c}) \para (a + \underline{c}.\underline{a}.a))$} 
and $q = a.a.\nil + \underline{a}.a.\nil$. It is not difficult to see that $p \not\sim_{step} q$, even if
for all  $r \in \mathcal{P}$, $p \para r \sim q \para r$.
\fine
\end{example}






